---
title: "lasso and rf"
author: "Brianna Carnagie"
date: "2024-04-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Option 2: Explore a provided dataset for pre-specified research goals

I decided to go with *Option C*, which involves constructing a propensity score to aid in an epidemiologic analysis of an etiologic question and then performing an analysis using the propensity score to address that etiologic question.

My research question is as follows: How does length of hospital stay vary by type of insurance coverage in urgent, surgical patients?

After considering the nature of my research question, I considered the following variables to be key to answering my research question,

*Primary Variables:*
* Length of Stay (length_of_stay): The primary outcome variable.
* Type of Insurance Coverage (payment_typology_1): The primary explanatory variable. This indicates the insurance coverage types of the patients.

*Control Variables:*
* Age Group (age_group): Older patients might stay longer in hospitals due to complications.
* APR Severity of Illness (apr_severity_of_illness_description): This might influence both the length of stay.
* APR Risk of Mortality (apr_risk_of_mortality): This is crucial as it likely correlates with both the severity of the illness.

# Step 1: Loading libraries

Self-explanatory, but my first step included loading the libraries I will be using for this project.
```{r, message=FALSE}
library(tidyverse)
library(MatchIt)
library(WeightIt)
library(randomForest)
library(caret)
library(tidyverse)
library(VIM)
library(dplyr)
library(nnet)
library(ranger)
library(progress)
library(glmnet)
library(pROC)
library(glmnet)
library(ggplot2)
library(cobalt)
```

# Step 2: Loading and cleaning the dataset

In my assignment prep, I loaded and refined the SPARCS dataset. Using read_csv, I imported the data and standardized column names with clean_names. I isolated surgical discharges via filter and grepl, removing irrelevant columns and rows with missing values. This streamlined dataset is now ready for detailed analysis, providing valuable insights into hospital discharge patterns.
```{r}
hospital_df = read_csv("/Users/briannacarnagie/Downloads/Hospital_Inpatient_Discharges__SPARCS_De-Identified___2015.csv") %>% janitor::clean_names() |>  filter(type_of_admission == "Urgent" & grepl("surgical", apr_medical_surgical_description, ignore.case = TRUE))

hospital_df$payment_typology_1 <- factor(hospital_df$payment_typology_1)


# Columns to delete
columns_to_delete <- c("health_service_area", "hospital_county", "operating_certificate_number", "facility_id", 
                       "facility_name", "zip_code_3_digits", "discharge_year", "ccs_diagnosis_code", 
                       "ccs_procedure_code", "ccs_procedure_description", 
                       "apr_drg_description", "apr_drg_code", "apr_severity_of_illness_code", "apr_mdc_code", "apr_mdc_description",   
                       "payment_typology_2", "payment_typology_3", "birth_weight", "abortion_edit_indicator", 
                       "emergency_department_indicator", "total_charges", "total_costs", "apr_medical_surgical_description", "type_of_admission")

# Delete columns
hospital_df <- hospital_df[, !(names(hospital_df) %in% columns_to_delete)]

# Deleting NA values
hospital_df<-na.omit(hospital_df)   
```

# Step 3: Propensity Score Estimation via Random Forest 

In defining my propensity score estimation model, I specified predictors such as age group, gender, race, ethnicity, type of admission, CCS diagnosis description, APR severity of illness description, and APR risk of mortality. The target variable for propensity score estimation was set as "payment_typology_1". Using these predictors and the target variable, I created a formula for the Random Forest model. To optimize the model, I defined a grid of hyperparameters including the number of variables to consider at each split (mtry), the splitting rule (splitrule), and the minimum number of observations in each terminal node (min.node.size). Employing k-fold cross-validation with 3 folds, I tuned the hyperparameters for the Random Forest model. Subsequently, I trained the Random Forest model with the best hyperparameters obtained from the tuning process. Finally, I extracted propensity scores from the trained model, enabling further analysis of treatment effects in the hospital discharge dataset.
```{r}
# Define predictors (covariates) for propensity score estimation
predictors <- c("age_group", "gender", "race", "ethnicity", "apr_severity_of_illness_description", "apr_risk_of_mortality")

# Define the target variable (treatment) for propensity score estimation
treatment <- "payment_typology_1"

# Create formula for Random Forest model
formula <- as.formula(paste(treatment, "~", paste(predictors, collapse = "+")))

# Define grid of hyperparameters for tuning
hyperparameters <- expand.grid(mtry = seq(2, length(predictors), by = 1), 
                               splitrule = c("gini"),
                               min.node.size = c(1, 5, 10))

# Perform k-fold cross-validation for hyperparameter tuning
ctrl <- trainControl(method = "cv", number = 3)
rf_tune <- train(formula, data = hospital_df, method = "ranger", trControl = ctrl, tuneGrid = hyperparameters)

# Get the best hyperparameters
best_mtry <- rf_tune$bestTune$mtry
best_splitrule <- rf_tune$bestTune$splitrule
best_min_node_size <- rf_tune$bestTune$min.node.size

rf_model <- ranger(payment_typology_1 ~ age_group + gender + race + ethnicity + apr_severity_of_illness_description + apr_risk_of_mortality, 
                   data = hospital_df, 
                   probability = TRUE, 
                   mtry = best_mtry, 
                   splitrule = best_splitrule, 
                   min.node.size = best_min_node_size,
                   num.trees = 500)

# Predict probabilities
propensity_scores_rf <- predict(rf_model, data = hospital_df, type = "response")
hospital_df$propensity_scores_rf <- propensity_scores_rf$predictions
```


# Step 3: Propensity Score Estimation via Multinomial Logistic Regression
```{r}

# Fit the multinomial logistic regression model
multinom_model <- multinom(payment_typology_1 ~ age_group + gender + race + ethnicity + apr_severity_of_illness_description + apr_risk_of_mortality, data = hospital_df)

# Summary of the model
summary(multinom_model)

# Predict the probabilities (propensity scores)
propensity_scores <- predict(multinom_model, type = "probs")

# Attach the propensity scores back to the dataframe
for (i in 1:ncol(propensity_scores)) {
  hospital_df[paste("PS_", colnames(propensity_scores)[i], sep = "")] <- propensity_scores[, i]
}
```

# Step 4:  Examine region of common support

This is common for propensity score analyses, to ensure that there is overlap in propensities among those who are in each insurance type group. For my RF plt, I first had to transform the matrix into a long format dataframe where each row corresponds to an observation and includes the insurance type and the associated propensity score (turn it into long format). This was done for the random forest and logistic regression plot.
```{r overlap}

# Adding a unique identifier to the dataframe before reshaping (if not already present)
hospital_df$ID <- seq_len(nrow(hospital_df))

# Convert the matrix of propensity scores to a dataframe and gather it to long format
long_propensity_scores <- as.data.frame(hospital_df$propensity_scores_rf)
long_propensity_scores$ID <- hospital_df$ID  # Append ID for merging
long_propensity_scores <- pivot_longer(long_propensity_scores, cols = -ID, names_to = "Insurance_Type", values_to = "Propensity_Score")

# Merge back with original data to include the `payment_typology_1` for faceting
long_propensity_scores <- merge(long_propensity_scores, hospital_df[, c("ID", "payment_typology_1")], by = "ID")

# Now plot the histogram of probabilities
ggplot(long_propensity_scores, aes(x = Propensity_Score)) +
    geom_histogram(bins = 30, fill = "green3", color = "black", alpha = 0.7) +
    facet_wrap(~ Insurance_Type, scales = "free") +
    theme_bw() +
    ggtitle("Overlap of Propensity Scores from Random Forest")

propensity_scores_long <- reshape2::melt(hospital_df, id.vars = "payment_typology_1", measure.vars = paste("PS_", colnames(propensity_scores), sep = ""))


ggplot(propensity_scores_long, aes(x = value)) +
  geom_histogram(bins = 30, fill = "pink3", color = "black", alpha = 0.7) +
  facet_wrap(~variable, scales = "free") +
  theme_bw() +
  ggtitle("Overlap of Propensity Scores from Multinomial Logistic Regression")

```


# Step 4: Model Comparison

In this code chunk, I assess covariate balance.
```{r}


# For Random Forest
bal.tab(hospital_df$propensity_scores_rf, data = hospital_df, treat = "payment_typology_1", method = "weighting", s.d.denom = "pooled", binary = "std")

weights <- weightit(treat ~ age_group + gender + race + ethnicity, 
                    data = hospital_df, 
                    method = "ps", 
                    estimand = "ATE", 
                    link = "logit")  # This is for binary; adjust accordingly for multinomial

# Now use these weights in the balance checking
bal.tab(data = hospital_df, treat = "payment_typology_1", 
        covs = c("age_group", "gender", "race", "ethnicity"),
        weights = weights$weights, 
        method = "weighting", 
        s.d.denom = "pooled", 
        binary = "std")

```





# Step 4: Using Propensity Score Weighting

In analyzing the length of hospital stay by insurance coverage, I first combined the propensity scores obtained earlier with the original dataset, creating a new dataset named data_with_propensity. I then utilized the propensity scores for balancing treatment groups, employing propensity score matching. By matching treatment groups based on propensity scores, I generated a subset of the dataset called matched_data. Subsequently, I proceeded to analyze the relationship between insurance coverage and length of hospital stay. I employed both linear regression, incorporating propensity scores as covariates. Finally, I assessed the results obtained from the model summary to evaluate the impact of insurance coverage on the length of hospital stay.
```{r}
# Define insurance types
insurance_types <- c("Medicaid", "Medicare", "Self-Pay", "Blue Cross/Blue Shield", "Private Health Insurance", "Federal/State/Local/VA", "Department of Corrections", "Miscellaneous/Other", "Managed Care, Unspecified", "Unknown")

# Initialize a list to store weighted datasets for each insurance type
weighted_datasets <- list()

# Loop through each insurance type
for (insurance_type in insurance_types) {
  # Create treatment indicator based on current insurance type
  treatment_indicator <- ifelse(hospital_df$payment_typology_1 == insurance_type, 1, 0)
  
  # Extract propensity scores for the current insurance type
  propensity_scores_insurance <- propensity_scores[[insurance_type]]
  
  # Calculate weights based on propensity scores for current insurance type
  weights <- ifelse(treatment_indicator == 1, 1 / propensity_scores_insurance, 1 / (1 - propensity_scores_insurance))
  
  # Assign weights to dataset
  weighted_df <- cbind(hospital_df, weights)
  
  # Store weighted dataset in the list
  weighted_datasets[[insurance_type]] <- weighted_df
}
```
